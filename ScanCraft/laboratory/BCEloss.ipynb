{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=numpy.load('data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.68757081e+00,   2.94078921e+02,   1.94531029e+03, ...,\n",
       "         -4.75633029e+02,   8.84171574e+02,   1.00000000e+00],\n",
       "       [  1.61253090e+01,   8.29991708e+02,   3.64348861e+02, ...,\n",
       "         -5.95314023e+01,   1.13626157e+03,   1.00000000e+00],\n",
       "       [  1.11925386e+01,   6.24943518e+02,   1.73264368e+03, ...,\n",
       "         -3.24915927e+02,   1.42349635e+03,   1.00000000e+00],\n",
       "       ..., \n",
       "       [  2.27990107e+01,   5.57724891e+02,   2.07736797e+02, ...,\n",
       "          2.35709254e+03,   1.36798789e+02,   0.00000000e+00],\n",
       "       [  5.59432889e+00,   9.26605099e+02,   1.57286028e+03, ...,\n",
       "          2.31249107e+02,   1.30897803e+03,   0.00000000e+00],\n",
       "       [  2.17510745e+01,   6.87385368e+02,   8.92191885e+02, ...,\n",
       "          2.90481760e+03,   5.92261210e+02,   0.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data=Variable(torch.FloatTensor(data[:,:-1]))\n",
    "target=Variable(torch.FloatTensor(data[:,-1].reshape(300,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 6.6876e+00  2.9408e+02  1.9453e+03  ...  -2.2558e+03 -4.7563e+02  8.8417e+02\n",
       " 1.6125e+01  8.2999e+02  3.6435e+02  ...   1.2169e+03 -5.9531e+01  1.1363e+03\n",
       " 1.1193e+01  6.2494e+02  1.7326e+03  ...   1.8701e+03 -3.2492e+02  1.4235e+03\n",
       "                ...                   ⋱                   ...                \n",
       " 2.2799e+01  5.5772e+02  2.0774e+02  ...  -2.1165e+03  2.3571e+03  1.3680e+02\n",
       " 5.5943e+00  9.2661e+02  1.5729e+03  ...   1.2081e+03  2.3125e+02  1.3090e+03\n",
       " 2.1751e+01  6.8739e+02  8.9219e+02  ...  -1.2834e+03  2.9048e+03  5.9226e+02\n",
       "[torch.FloatTensor of size 300x12]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Linear (12 -> 100)\n",
       "  (1): Linear (100 -> 10)\n",
       "  (2): Linear (10 -> 1)\n",
       "  (3): Sigmoid ()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll=loss(model(in_data),target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "global in_data,model,loss,out,ll\n",
    "def BCE(calable):\n",
    "    out_data=model(in_data)    \n",
    "    ll=loss(out_data,target)\n",
    "    model.zero_grad()\n",
    "    ll.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 15.1051\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.data-=0.001*param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1472 -0.0464  0.0765  ...  -0.2173  0.2304  0.1034\n",
      "-0.1074 -0.2234 -0.1048  ...   0.2068 -0.1160  0.0182\n",
      "-0.2868  0.0634 -0.2253  ...   0.2824  0.2678  0.2457\n",
      "          ...             ⋱             ...          \n",
      "-0.0909 -0.1827 -0.0698  ...  -0.1317  0.1477 -0.0642\n",
      "-0.2521  0.2733  0.1847  ...  -0.1818 -0.1312 -0.1699\n",
      " 0.1798  0.0990  0.0170  ...   0.0193 -0.1055 -0.2731\n",
      "[torch.FloatTensor of size 100x12]\n",
      "\n",
      "\n",
      " 0.0761\n",
      "-0.2729\n",
      " 0.1995\n",
      "-0.0763\n",
      "-0.0946\n",
      " 0.2781\n",
      " 0.2221\n",
      " 0.2229\n",
      "-0.0393\n",
      " 0.1229\n",
      " 0.0718\n",
      " 0.1643\n",
      " 0.1480\n",
      " 0.1663\n",
      "-0.2718\n",
      "-0.1818\n",
      "-0.0742\n",
      " 0.2249\n",
      " 0.1466\n",
      " 0.1743\n",
      "-0.2246\n",
      " 0.1070\n",
      "-0.0364\n",
      "-0.0701\n",
      " 0.2605\n",
      "-0.1759\n",
      " 0.2585\n",
      "-0.1284\n",
      "-0.1284\n",
      " 0.0318\n",
      " 0.0715\n",
      "-0.1525\n",
      " 0.1622\n",
      " 0.1230\n",
      " 0.2526\n",
      "-0.2014\n",
      "-0.0828\n",
      " 0.1294\n",
      "-0.0489\n",
      " 0.2411\n",
      "-0.2367\n",
      "-0.1752\n",
      " 0.0759\n",
      " 0.1883\n",
      " 0.1130\n",
      "-0.2134\n",
      " 0.2388\n",
      " 0.1429\n",
      "-0.0950\n",
      " 0.1083\n",
      " 0.0125\n",
      "-0.0826\n",
      "-0.2556\n",
      " 0.1083\n",
      " 0.0698\n",
      "-0.0921\n",
      "-0.0464\n",
      " 0.2878\n",
      " 0.2832\n",
      "-0.1969\n",
      " 0.1661\n",
      "-0.0909\n",
      "-0.0547\n",
      "-0.1998\n",
      " 0.0451\n",
      "-0.1684\n",
      " 0.1803\n",
      " 0.2182\n",
      "-0.2528\n",
      "-0.0841\n",
      "-0.1793\n",
      "-0.1419\n",
      "-0.0768\n",
      "-0.2476\n",
      "-0.2298\n",
      " 0.1239\n",
      " 0.1695\n",
      "-0.2672\n",
      "-0.2346\n",
      " 0.1730\n",
      " 0.2576\n",
      " 0.0817\n",
      " 0.0119\n",
      "-0.0050\n",
      " 0.0465\n",
      " 0.1256\n",
      "-0.0563\n",
      " 0.1507\n",
      " 0.0468\n",
      "-0.1795\n",
      "-0.1382\n",
      "-0.0802\n",
      " 0.1496\n",
      "-0.0339\n",
      " 0.1807\n",
      "-0.1897\n",
      "-0.2515\n",
      "-0.1854\n",
      " 0.2841\n",
      "-0.0917\n",
      "[torch.FloatTensor of size 100]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      " 2.8845  6.6966 -9.2166  ...  -7.2587 -5.7946 -4.9435\n",
      "-3.7985 -1.6853 -8.4985  ...   2.7155 -0.0113 -5.5503\n",
      "-4.1157  5.3769 -4.2767  ...   9.4863 -3.2120 -2.7363\n",
      "          ...             ⋱             ...          \n",
      "-6.3140 -6.7175  5.5092  ...  -7.1719 -4.9163 -9.6371\n",
      " 3.2029 -6.9720 -6.7742  ...   6.9223 -4.6073  4.1979\n",
      " 7.9213 -9.3430  8.3499  ...  -9.4207  3.3397  2.8144\n",
      "[torch.FloatTensor of size 10x100]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      " -5.5353\n",
      "  8.2766\n",
      "  4.4747\n",
      " -5.7366\n",
      " -5.5777\n",
      " -8.0063\n",
      " -9.7315\n",
      " -1.7702\n",
      "  6.1503\n",
      "  4.2213\n",
      "[torch.FloatTensor of size 10]\n",
      "\n",
      "\n",
      "-0.0778 -0.1806  0.1581  0.0268 -0.1545  0.3027  0.2917 -0.2771  0.1111  0.2211\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n",
      "\n",
      " 0.2172\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3.8281\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0080\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0036\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0001\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       " 0.0000\n",
       " 1.0000\n",
       " 0.0000\n",
       "[torch.FloatTensor of size 300x1]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (\n",
       "  (0): Linear (12 -> 100)\n",
       "  (1): Linear (100 -> 10)\n",
       "  (2): Linear (10 -> 1)\n",
       "  (3): Sigmoid ()\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
